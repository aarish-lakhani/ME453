{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from matplotlib import colors\n",
    "import pylab as plt\n",
    "from skimage import io\n",
    "import matplotlib.ticker as plticker\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Plot options\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaris\n"
     ]
    }
   ],
   "source": [
    "# Access Manually Identified Bowties\n",
    "# print(os.getcwd())\n",
    "# os.chdir(\"..\")\n",
    "os.chdir(\"./Topic 2/Topic 2/Manually Identified Bowties/\") \n",
    "\n",
    "l0bowtie = [k for k in os.listdir() if '_0.npy' in k] # create a list with all 0 degree images from manually identified bowties\n",
    "l45bowtie = [k for k in os.listdir() if '_45.npy' in k] # create a list with all 45 degree images from manually identified bowties\n",
    "\n",
    "# Access Manually Identified Other\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"./Manually Identified Other/\") \n",
    "\n",
    "l0other = [k for k in os.listdir() if '_0.npy' in k] # create a list with all 0 degree images from manually identified other\n",
    "l45other = [k for k in os.listdir() if '_45.npy' in k] # create a list with all 45 degree images from manually identified other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.chdir(\"./Manually Identified Bowties/\") \n",
    "\n",
    "var = 40 # if convolved image, change to 38 (otherwise, leave at 40)\n",
    "\n",
    "l0b = torch.empty([int(len(l0bowtie)), 1, var, var])\n",
    "count0b = 0\n",
    "\n",
    "for i in range(0, len(l0bowtie)):\n",
    "    newArray = np.load(l0bowtie[i])\n",
    "\n",
    "    if newArray.shape == (var, var):\n",
    "        l0b[i] = torch.from_numpy(newArray) \n",
    "        count0b += 1\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Array Shape: {newArray.shape}\")\n",
    "    #     print(f\"hey this isn't working!!!\")\n",
    "\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"./Manually Identified Other/\") \n",
    "\n",
    "l0o = torch.empty([int(len(l0other)), 1, var, var])\n",
    "count0o = 0\n",
    "\n",
    "for i in range(0, len(l0other)):\n",
    "    newArray = np.load(l0other[i])\n",
    "\n",
    "    if newArray.shape == (var, var):\n",
    "        l0o[i] = torch.from_numpy(newArray)\n",
    "        count0o += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 990\n",
      "Training Set Shape: torch.Size([990, 1, 40, 40])\n",
      "Testing Set Shape: torch.Size([990])\n"
     ]
    }
   ],
   "source": [
    "total = count0b + count0o\n",
    "print(f\"Number of Images: {total}\")\n",
    "x = torch.cat((l0b[0:count0b], l0o[0:count0o]), 0)\n",
    "print(f\"Training Set Shape: {x.shape}\")\n",
    "\n",
    "y1 = torch.ones(count0b)\n",
    "y2 = torch.zeros(count0o)\n",
    "y = torch.cat((y1, y2), 0)\n",
    "print(f\"Testing Set Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape: torch.Size([792, 1, 40, 40])\n",
      "ytrain shape: torch.Size([792])\n",
      "xtest shape: torch.Size([198, 1, 40, 40])\n",
      "ytest shape: torch.Size([198])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "idx = torch.randperm(total)\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "\n",
    "trainingSet = round(total*0.8)\n",
    "xtrain = x[:trainingSet]\n",
    "xtest = x[trainingSet:]\n",
    "ytrain = y[:trainingSet]\n",
    "ytest = y[trainingSet:]\n",
    "\n",
    "print(f\"xtrain shape: {xtrain.shape}\")\n",
    "print(f\"ytrain shape: {ytrain.shape}\")\n",
    "print(f\"xtest shape: {xtest.shape}\")\n",
    "print(f\"ytest shape: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, (3, 3), padding = 'same'), # 10x40x40\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #10x20x20\n",
    "            nn.Conv2d(10, 20, (3, 3), padding = 'same'), #20x20x20\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #20x10x10\n",
    "            nn.Conv2d(20, 40, (3, 3), padding = 'same'), # 40x10x10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 40x5x5\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fullyConnected = nn.Sequential(\n",
    "            nn.Linear(1000, 10), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2) # Output is 0 or 1    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fullyConnected(x)\n",
    "        return x\n",
    "    \n",
    "net = convNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the task\n",
    "num_epochs = 80\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = convNeuralNetwork()\n",
    "\n",
    "# Set loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Loss:0.0000\n",
      "Epoch [1/80], Test Accuracy:100.0000\n",
      "Epoch [2/80], Loss:0.0000\n",
      "Epoch [3/80], Loss:0.0001\n",
      "Epoch [4/80], Loss:0.0000\n",
      "Epoch [5/80], Loss:0.0000\n",
      "Epoch [6/80], Loss:0.0000\n",
      "Epoch [7/80], Loss:0.0000\n",
      "Epoch [8/80], Loss:0.0000\n",
      "Epoch [9/80], Loss:0.0000\n",
      "Epoch [10/80], Loss:0.0000\n",
      "Epoch [11/80], Loss:0.0000\n",
      "Epoch [11/80], Test Accuracy:100.0000\n",
      "Epoch [12/80], Loss:0.0000\n",
      "Epoch [13/80], Loss:0.0000\n",
      "Epoch [14/80], Loss:0.0000\n",
      "Epoch [15/80], Loss:0.0000\n",
      "Epoch [16/80], Loss:0.0000\n",
      "Epoch [17/80], Loss:0.0000\n",
      "Epoch [18/80], Loss:0.0000\n",
      "Epoch [19/80], Loss:0.0000\n",
      "Epoch [20/80], Loss:0.0000\n",
      "Epoch [21/80], Loss:0.0000\n",
      "Epoch [21/80], Test Accuracy:100.0000\n",
      "Epoch [22/80], Loss:0.0000\n",
      "Epoch [23/80], Loss:0.0000\n",
      "Epoch [24/80], Loss:0.0000\n",
      "Epoch [25/80], Loss:0.0000\n",
      "Epoch [26/80], Loss:0.0000\n",
      "Epoch [27/80], Loss:0.0000\n",
      "Epoch [28/80], Loss:0.0000\n",
      "Epoch [29/80], Loss:0.0000\n",
      "Epoch [30/80], Loss:0.0000\n",
      "Epoch [31/80], Loss:0.0000\n",
      "Epoch [31/80], Test Accuracy:100.0000\n",
      "Epoch [32/80], Loss:0.0000\n",
      "Epoch [33/80], Loss:0.0000\n",
      "Epoch [34/80], Loss:0.0000\n",
      "Epoch [35/80], Loss:0.0000\n",
      "Epoch [36/80], Loss:0.0000\n",
      "Epoch [37/80], Loss:0.0000\n",
      "Epoch [38/80], Loss:0.0000\n",
      "Epoch [39/80], Loss:0.0000\n",
      "Epoch [40/80], Loss:0.0000\n",
      "Epoch [41/80], Loss:0.0000\n",
      "Epoch [41/80], Test Accuracy:100.0000\n",
      "Epoch [42/80], Loss:0.0000\n",
      "Epoch [43/80], Loss:0.0000\n",
      "Epoch [44/80], Loss:0.0000\n",
      "Epoch [45/80], Loss:0.0000\n",
      "Epoch [46/80], Loss:0.0000\n",
      "Epoch [47/80], Loss:0.0000\n",
      "Epoch [48/80], Loss:0.0000\n",
      "Epoch [49/80], Loss:0.0000\n",
      "Epoch [50/80], Loss:0.0000\n",
      "Epoch [51/80], Loss:0.0000\n",
      "Epoch [51/80], Test Accuracy:100.0000\n",
      "Epoch [52/80], Loss:0.0000\n",
      "Epoch [53/80], Loss:0.0000\n",
      "Epoch [54/80], Loss:0.0000\n",
      "Epoch [55/80], Loss:0.0000\n",
      "Epoch [56/80], Loss:0.0000\n",
      "Epoch [57/80], Loss:0.0000\n",
      "Epoch [58/80], Loss:0.0000\n",
      "Epoch [59/80], Loss:0.0000\n",
      "Epoch [60/80], Loss:0.0000\n",
      "Epoch [61/80], Loss:0.0000\n",
      "Epoch [61/80], Test Accuracy:100.0000\n",
      "Epoch [62/80], Loss:0.0000\n",
      "Epoch [63/80], Loss:0.0000\n",
      "Epoch [64/80], Loss:0.0000\n",
      "Epoch [65/80], Loss:0.0000\n",
      "Epoch [66/80], Loss:0.0000\n",
      "Epoch [67/80], Loss:0.0000\n",
      "Epoch [68/80], Loss:0.0000\n",
      "Epoch [69/80], Loss:0.0000\n",
      "Epoch [70/80], Loss:0.0000\n",
      "Epoch [71/80], Loss:0.0000\n",
      "Epoch [71/80], Test Accuracy:100.0000\n",
      "Epoch [72/80], Loss:0.0000\n",
      "Epoch [73/80], Loss:0.0000\n",
      "Epoch [74/80], Loss:0.0000\n",
      "Epoch [75/80], Loss:0.0000\n",
      "Epoch [76/80], Loss:0.0000\n",
      "Epoch [77/80], Loss:0.0000\n",
      "Epoch [78/80], Loss:0.0000\n",
      "Epoch [79/80], Loss:0.0000\n",
      "Epoch [80/80], Loss:0.0000\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "net.train()\n",
    "total_step = len(xtrain)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    for i in range(0, len(xtrain), batch_size):\n",
    "        # obtain inputs\n",
    "        x, y = xtrain[i : i + batch_size], ytrain[i : i + batch_size]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(x)\n",
    "        loss = criterion(output, y.type(torch.long)) # convert float tensor to integer tensor\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # append loss statistic\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss.append(running_loss / total_step)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss:{train_loss[-1]:.4f}\")\n",
    "\n",
    "    # Test loss\n",
    "    with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(0, len(xtest), batch_size):\n",
    "            # obtain inputs\n",
    "            x, y = xtest[i : i + batch_size], ytest[i : i + batch_size]\n",
    "\n",
    "            # run images through network and obtain output\n",
    "            output = net(x)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == y).sum()\n",
    "            total += y.size(0)\n",
    "            \n",
    "        accuracy = (100 * correct / total).item()\n",
    "        test_accuracy.append(accuracy)\n",
    "    if epoch % 10 == 0: # Print every 10 epochs\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy:{test_accuracy[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81af19a19d6cb113ed37e4965a0bda39104e0aa754cd78de77b62e483bacdde2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
